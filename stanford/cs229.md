# [CS229](): Machine Learning

- **Code**: /stanford/cs229
- **Author**: Andrew Ng
- **Instructor**: Andrew Ng
- **Institution**: Stanford University
- **Course Website**: [http://cs229.stanford.edu](http://cs229.stanford.edu)


About this document: this is an
[Athena Linked Syllabus](https://athena.ai/about/linked-syllabus).
It is an annotated outline of a body of knowledge.
Here, this one outlines a university course, including class lecture notes,
handouts, problem sets, and topics.
Any concepts mentioned here are linked to their respective page in the
[Athena Knowledge Graph](https://athena.ai/about/knowledge-graph), where
you can find explanations, exercises, and
[concept dependencies](https://athena.ai/about/concept-dependencies).
The concept links will also
[show your mastery](https://athena.ai/about/concept-mastery).
Read more [here](https://athena.ai/about/linked-syllabus).

All content linked here is the property of its respective author(s).

### Table of Contents

[tableofcontents]


## Prerequisites


### [cs109](https://alpha.athena.ai/stanford/cs109) or [stats116](https://alpha.athena.ai/stanford/stats116)


### [cs106b](https://alpha.athena.ai/stanford/cs106b) or [cs106x](https://alpha.athena.ai/stanford/cs106x)


### [math51](https://alpha.athena.ai/stanford/math51) or [math103](https://alpha.athena.ai/stanford/math103) or [math113](https://alpha.athena.ai/stanford/math113) or [cs205](https://alpha.athena.ai/stanford/cs205)


## Outline

- Introduction (1 class)
  1. Basic concepts.

- [Supervised learning]() (7 classes)
  1. Supervised learning setup.
     [LMS]().
  1. [Logistic regression]().
     [Perceptron]().
     [Exponential family]().
  1. [Generative learning algorithms]().
     [Gaussian discriminant analysis]().
     [Naive Bayes]().
  1. [Support vector machines]().
  1. [Model selection]() and [feature selection]().
  1. [Ensemble methods](): [Bagging](), [boosting]().
  1. Evaluating and debugging learning algorithms.

- [Learning theory](). (3 classes)
  1. [Bias/variance tradeoff]().
     Union and
     [Chernoff]()/[Hoeffding]() bounds.
  1. [VC dimension](). Worst case (online) learning.
  1. Practical advice on how to use learning algorithms.

- [Unsupervised learning](). (5 classes)
  1. [Clustering]().
     [K-means]().
  1. [EM]().
     [Mixture of Gaussians]().
  1. [Factor analysis]().
  1. PCA ([Principal components analysis]()).
  1. ICA ([Independent components analysis]()).

- [Reinforcement learning]() and control. (4 classes)
  1. [MDPs](). [Bellman equations]().
  1. [Value iteration]() and [policy iteration]().
  1. [Linear quadratic regulation]() (LQR). LQG.
  1. [Q-learning](). [Value function approximation]().
  1. [Policy search](). [Reinforce](). [POMDPs]().


## Handouts and Problem Sets

- [Course Schedule](http://cs229.stanford.edu/schedule.html)
- [Handout #1: Course Information (HTML)](http://cs229.stanford.edu/info.html)
- [Handout #2: Course Schedule (HTML)](http://cs229.stanford.edu/schedule.html)
- [Handout #3: Final Project Guidelines (PDF)new](http://cs229.stanford.edu/materials/projectGuidelines.pdf)
- [Problem Set 1 (pdf)](http://cs229.stanford.edu/materials/ps1.pdf)
  Data: [q1x.dat](http://cs229.stanford.edu/ps/ps1/q1x.dat),
  [q1y.dat](http://cs229.stanford.edu/ps/ps1/q1y.dat),
  [q2x.dat](http://cs229.stanford.edu/ps/ps1/q2x.dat),
  [q2y.dat](http://cs229.stanford.edu/ps/ps1/q2y.dat)
- [Problem Set 2 (pdf)](http://cs229.stanford.edu/materials/ps2.pdf)
  Data: [ps2.zip](http://cs229.stanford.edu/ps/ps2/ps2.zip)
- [Problem Set 3 (pdf)](http://cs229.stanford.edu/materials/ps3.pdf)
  Data: [mandrill-small.tiff](http://cs229.stanford.edu/materials/mandrill-small.tiff),
  [mandrill-large.tiff](http://cs229.stanford.edu/materials/mandrill-large.tiff)
- [Problem Set 4 (pdf)](http://cs229.stanford.edu/materials/ps4.pdf)
  Data: [q4.zip](http://cs229.stanford.edu/ps/ps4/q4.zip),
  [q6.zip](http://cs229.stanford.edu/ps/ps4/q6.zip)
- [Practice Midterm (pdf)](http://cs229.stanford.edu/materials/practice-midterm.pdf)


## Lecture Notes


### Lec. Notes 1: Supervised Learning and Discriminative Algorithms

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes1.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes1.pdf)

Concepts Taught:


- Part I: [Supervised Learning]()
  - Terminology
    - [Dataset]()
    - [Input Features]()
    - [Target Variable]()
    - [Training Example]()
    - [Training Set]()
    - [Predictor]()
    - [Hypothesis Function]()
    - [Learning Algorithm]()
    - [Learning Problem]()
    - [Regression problem]()
    - [Classification problem]()
  - [Linear Regression]()
    - [Parameters]()
    - [Intercept Term]()
    - [Cost Function]()
    - [Least-Squares Cost Function]()
    - [Ordinary Least Squares]()
    - [Least Mean Squares Algorithm]()
      - [Gradient Descent Algorithm]()
      - [Learning Rate]()
      - [Update Rule]()
      - [Widrow-Hoï¬€ Learning Rule]()
      - [Error Term]()
      - [Batch Gradient Descent]()
      - [Convex Function]()
      - [Stochastic Gradient Descent]()
    - [Normal Equations]()
      - [Matrix Derivatives]()
      - [trace operator]()
      - [Design Matrix]()
    - Probabilistic Interpretation
      - [Likelihood Function]()
      - [Maximum Likelihood Principle]()
      - [Log Likelihood Function]()
    - [Locally Weighted Linear Regression]()
      - [Underfitting]()
      - [Overfitting]()
      - [Bandwidth Parameter]()
      - [Non-Parametric Learning Algorithm]()
      - [Parametric Learning Algorithm]()
- Part II:
  [Classification]() and
  [Logistic Regression]()
  - Terminology
    - [Binary Classification]()
    - [Training Example Label]()
  - [Logistic Regression]()
    - [Logistic Function]()
    - [Maximum Likelihood with Logistic Regression]()
    - [Logistic Regression Gradient Ascent]()
  - [Perceptron Learning Algorithm]()
  - Maximizing with Newton's Method
    - [Newton-Raphson Method]()
    - [Hessian Matrix]()
    - [Fisher Scoring]()
- Part III: [Generalized Linear Models]()
  - [Exponential Family Distributions]()
    - [Natural Parameter]() or [Canonical Parameter]()
    - [Sufficient Statistic]()
    - [Log Partition Function]()
    - [Distribution Family]()
    - [Bernouilli as Exponential Family Distribution]()
    - [Normal as Exponential Family Distribution]()
    - [Dispersion Parameter]()
  - [Constructing Generalized Linear Models]()
    - [Ordinary Least Squares as Generalized Linear Model]()
    - [Logistic Regression as Generalized Linear Model]()
      - [Canonical Response Function]()
      - [Canonical Link Function]()
    - [Softmax Regression as Generalized Linear Model]()
      - [Multinomial as Exponential Family Distribution]()
      - [Softmax Regression]()


Concepts Required

- [Linear Algebra]()
  - [Matrix Arithmetic]()

- [Probability Theory]()
  - [Normal Distribution]()
  - [IID RVs]()
  - [Maximum Likelihood Estimate]()



### Lec. Notes 2: Generative Algorithms

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes2.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes2.pdf)

Concepts Taught:


### Lec. Notes 3: Support Vector Machines

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes3.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes3.pdf)

Concepts Taught:


### Lec. Notes 4: Learning Theory

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes4.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes4.pdf)

Concepts Taught:


### Lec. Notes 5: Regularization and Model Selection

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes5.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes5.pdf)

Concepts Taught:


### Lec. Notes 6: Online Learning and the Perceptron Algorithm. (optional reading)

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes6.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes6.pdf)

Concepts Taught:


### Lec. Notes 7a: Unsupervised Learning, k-means clustering.

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes7a.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes7a.pdf)

Concepts Taught:


### Lec. Notes 7b: Mixture of Gaussians

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes7b.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes7b.pdf)

Concepts Taught:


### Lec. Notes 8: The EM Algorithm

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes8.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes8.pdf)

Concepts Taught:


### Lec. Notes 9: Factor Analysis

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes9.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes9.pdf)

Concepts Taught:


### Lec. Notes 10: Principal Components Analysis

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes10.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes10.pdf)

Concepts Taught:


### Lec. Notes 11: Independent Components Analysis

Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes11.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes11.pdf)

Concepts Taught:


### Lec. Notes 12: Reinforcement Learning and Control


Notes:
[ps](http://cs229.stanford.edu/notes/cs229-notes12.ps),
[pdf](http://cs229.stanford.edu/notes/cs229-notes12.pdf)

Concepts Taught:



## Section Notes


### Section notes 1:  Linear Algebra Review and Reference

Notes: [pdf](http://cs229.stanford.edu/section/cs229-linalg.pdf)

Concepts Taught:


### Section notes 2:  Probability Theory Review

Notes: [pdf](http://cs229.stanford.edu/section/cs229-prob.pdf)

Concepts Taught:


### Matlab tutorial

Files:
[sigmoid.m](http://cs229.stanford.edu/section/matlab/sigmoid.m),
[logistic_grad_ascent.m](http://cs229.stanford.edu/section/matlab/logistic_grad_ascent.m),
[matlab_session.m](http://cs229.stanford.edu/section/matlab/matlab_session.m)

Concepts Taught:


### Section notes 4:  Convex Optimization Overview, Part I

Notes:
[ps](http://cs229.stanford.edu/section/cs229-cvxopt.ps),
[pdf](http://cs229.stanford.edu/section/cs229-cvxopt.pdf)

Concepts Taught:


### Section notes 5:  Convex Optimization Overview, Part II

Notes:
[ps](http://cs229.stanford.edu/section/cs229-cvxopt2.ps),
[pdf](http://cs229.stanford.edu/section/cs229-cvxopt2.pdf)

Concepts Taught:


### Section notes 6:  Hidden Markov Models

Notes:
[ps](http://cs229.stanford.edu/section/cs229-hmm.ps),
[pdf](http://cs229.stanford.edu/section/cs229-hmm.pdf)

Concepts Taught:


### Section notes 7:  The Multivariate Gaussian Distribution

Notes: [pdf](http://cs229.stanford.edu/section/gaussians.pdf)

Concepts Taught:

### Section notes 8:  More on Gaussian Distribution

Notes: [pdf](http://cs229.stanford.edu/section/more_on_gaussians.pdf)

Concepts Taught:

### Section notes 9:  Gaussian Processes

Notes: [pdf](http://cs229.stanford.edu/section/cs229-gaussian_processes.pdf)

Concepts Taught:


##  Other resources

Advice on applying machine learning: Slides from Andrew's lecture on getting
machine learning algorithms to work in practice can be found
[here](http://cs229.stanford.edu/materials/ML-advice.pdf).

Previous projects: A list of last year's final projects can be found
[here](http://cs229.stanford.edu/projects2011.html).


### Matlab, Octave

Matlab resources: Here are a couple of Matlab tutorials that you might find
helpful: http://www.math.ufl.edu/help/matlab-tutorial/ and
http://www.math.mtu.edu/~msgocken/intro/node1.html. For emacs users only: If
you plan to run Matlab in emacs, here are
[matlab.el](http://cs229.stanford.edu/materials/matlab.el), and a helpful
[.emacs](http://cs229.stanford.edu/materials/emacs) file.

Octave resources: For a free alternative to Matlab, check out
[GNU Octave](http://www.gnu.org/software/octave/). The official documentation
is available [here](http://www.gnu.org/software/octave/doc/interpreter/). Some
useful tutorials on Octave include
http://en.wikibooks.org/wiki/Octave_Programming_Tutorial and
http://www-mdp.eng.cam.ac.uk/web/CD/engapps/octave/octavetut.pdf .

### Data
Here is the [UCI Machine learning repository](http://www.ics.uci.edu/~mlearn/MLRepository.html), which contains a
large collection of standard datasets for testing learning algorithms. If you
want to see examples of recent work in machine learning, start by taking a look
at the conferences [NIPS](http://www.nips.cc/) (all old NIPS papers are online)
and ICML. Some other related conferences include UAI, AAAI, IJCAI.

### Viewing PostScript and PDF files

Depending on the computer you are using, you
may be able to download a [PostScript viewer](http://www.cs.wisc.edu/~ghost/)
or [PDF viewer](http://get.adobe.com/reader/otherversions/) for it if you don't
already have one.
